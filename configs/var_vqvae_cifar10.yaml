model:
  type: VAR_VQVAE
  vocab_size: 4096
  z_channels: 32
  ch: 128
  dropout: 0.05
  ch_mult: [1, 2, 2]
  num_res_blocks: 2
  share_quant_resi: 4
  v_patch_nums: [1, 2, 3, 4, 5, 6, 8]
  test_mode: false
dataset_type: CIFAR10
collate_keys: [img]
data_preprocessor:
  type: ImgDataPreprocessor
  minmax: false
  mean: [125.307, 122.950, 113.865]
  std: [62.993, 62.089, 66.705]
data_root: data/cifar10
train_dataloader:
  batch_size: 128
  sampler:
    type: DistributedSampler
    shuffle: true
  collate_keys: ${collate_keys}
  dataset:
    type: ${dataset_type}
    data_root: ${data_root}
    test_mode: false
val_dataloader:
  batch_size: 1024
  sampler:
    type: DistributedEvalSampler
    shuffle: false
  collate_keys: ${collate_keys}
  dataset:
    type: ${dataset_type}
    data_root: ${data_root}
    test_mode: true
evaluator:
  type: Evaluator
  metrics:
  - type: PeakSignalNoiseRatio
#  - type: FrechetInceptionDistance
#    batch_size: 500
train_epochs: 200
optimizer:
  type: AdamW
  lr: 3.0e-4
  betas: [0.5, 0.9]
  weight_decay: 0.005
scheduler:
  type: CosineLR
  t_initial: ${train_epochs}
  lr_min: 1.0e-5
  t_in_epochs: true
visualizer:
  type: ImgVisualizer
  use_tensorboard: true
seed: 0
use_amp: true
#eval_interval: ${train_epochs}
ckpt_interval: 10
